{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from python_speech_features import mfcc, fbank, delta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.io.wavfile as wav\n",
    "import subprocess\n",
    "import os, time, pickle\n",
    "import random\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "phn_61 = ['aa', 'ae', 'ah', 'ao', 'aw', 'ax', 'ax-h', 'axr', 'ay', 'b', 'bcl', 'ch', 'd', 'dcl', 'dh',\n",
    "          'dx', 'eh', 'el', 'em', 'en', 'eng', 'epi', 'er', 'ey', 'f', 'g', 'gcl', 'h#', 'hh', 'hv', \n",
    "          'ih', 'ix', 'iy', 'jh', 'k', 'kcl', 'l', 'm', 'n', 'ng', 'nx', 'ow', 'oy', 'p', 'pau', 'pcl',\n",
    "          'q', 'r', 's', 'sh', 't', 'tcl', 'th', 'uh', 'uw', 'ux', 'v', 'w', 'y', 'z', 'zh']\n",
    "\n",
    "mapping = {'ah': 'ax', 'ax-h': 'ax', 'ux': 'uw', 'aa': 'ao', 'ih': 'ix',\n",
    "               'axr': 'er', 'el': 'l', 'em': 'm', 'en': 'n', 'nx': 'n',\n",
    "               'eng': 'ng', 'sh': 'zh', 'hv': 'hh', 'bcl': 'h#', 'pcl': 'h#',\n",
    "               'dcl': 'h#', 'tcl': 'h#', 'gcl': 'h#', 'kcl': 'h#',\n",
    "               'q': 'h#', 'epi': 'h#', 'pau': 'h#'}\n",
    "\n",
    "phn_39 = ['ae', 'ao', 'aw', 'ax', 'ay', 'b', 'ch', 'd', 'dh', 'dx', 'eh', \n",
    "             'er', 'ey', 'f', 'g', 'h#', 'hh', 'ix', 'iy', 'jh', 'k', 'l', \n",
    "             'm', 'n', 'ng', 'ow', 'oy', 'p', 'r', 's', 't', 'th', 'uh', 'uw',\n",
    "             'v', 'w', 'y', 'z', 'zh']\n",
    "\n",
    "development_set = ['FAKS0', 'MMDB1', 'MBDG0', 'FEDW0', 'MTDT0', 'FSEM0', 'MDVC0', 'MRJM4', 'MJSW0', 'MTEB0',\n",
    "                    'FDAC1', 'MMDM2', 'MBWM0', 'MGJF0', 'MTHC0', 'MBNS0', 'MERS0', 'FCAL1', 'MREB0', 'MJFC0',\n",
    "                    'FJEM0', 'MPDF0', 'MCSH0', 'MGLB0', 'MWJG0', 'MMJR0', 'FMAH0', 'MMWH0', 'FGJD0', 'MRJR0',\n",
    "                    'MGWT0', 'FCMH0', 'FADG0', 'MRTK0', 'FNMK0', 'MDLS0', 'FDRW0', 'FJSJ0', 'FJMG0', 'FMML0',\n",
    "                    'MJAR0', 'FKMS0', 'FDMS0', 'MTAA0', 'FREW0', 'MDLF0', 'MRCS0', 'MAJC0', 'MROA0', 'MRWS1']\n",
    "\n",
    "core_test_set = ['MDAB0', 'MFBT0', 'FELC0', 'MTAS1', 'MFEW0', 'FPAS0', 'MJMP0', 'MLNT0', 'FPKT0',\n",
    "                'MLLL0', 'MTLS0', 'FJLM0', 'MBPM0', 'MKLT0', 'FNLP0', 'MCMJ0', 'MJDH0', 'FMGD0',\n",
    "                'MGRT0', 'MNJM0', 'FDHC0', 'MJLN0', 'MPAM0', 'FMLD0']\n",
    "\n",
    "TIMIT_DIR = './' # root directory for timit, it would be joined with timit/train or timit/test\n",
    "TFRECORD_DIR = './data' # directory for tfrecords files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_timit_dataset(train_set=True, dev_set=True, test_set=True, feats_type='mfcc'):\n",
    "    \n",
    "    def phase_randomization(signal, delta):\n",
    "        stft = librosa.stft(signal, n_fft=400, hop_length=160, win_length=400, window='hann')\n",
    "        phase = np.angle(stft)\n",
    "        num_cols = phase.shape[1]\n",
    "        \n",
    "        for i in range(num_cols):\n",
    "            mu = np.random.normal(1, delta)\n",
    "            phase[:, i] *= mu\n",
    "        \n",
    "        return phase\n",
    "    \n",
    "    def create_tfrecords(tfrecord_path, root_dir, fname, filter_fn):\n",
    "        writer = tf.io.TFRecordWriter(os.path.join(tfrecord_path, (fname + '.tfrecords')))\n",
    "        feats_list = []\n",
    "        phoneme_list = []\n",
    "        start = time.time()\n",
    "        cnt = 0\n",
    "\n",
    "        for path, dirs, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if filter_fn(file, path):\n",
    "                    continue\n",
    "                if file.endswith('WAV'):\n",
    "                    fullFileName = os.path.join(path, file)\n",
    "                    fnameNoSuffix = os.path.splitext(fullFileName)[0]\n",
    "                    fNameTmp = fnameNoSuffix + '.WAV'\n",
    "                    # convert nist file format to wav with command line program 'sox'\n",
    "                    subprocess.call(['sox', fullFileName, fNameTmp], shell=True)\n",
    "                    rate, sig = wav.read(fNameTmp)\n",
    "                    os.remove(fNameTmp)\n",
    "                    sig = sig.astype(np.float32)\n",
    "                    \n",
    "                    phase_randomized = phase_randomization(sig, delta=0.1)\n",
    "\n",
    "                    freq_mask_width = np.random.randint(10, 30)  \n",
    "                    freq_mask_start = np.random.randint(0, phase_randomized.shape[0] - freq_mask_width)\n",
    "                    phase_randomized[freq_mask_start:freq_mask_start + freq_mask_width, :] = 0\n",
    "                    \n",
    "                    time_mask_width = np.random.randint(5, phase_randomized.shape[1] // 9)  \n",
    "                    time_mask_start = np.random.randint(0, phase_randomized.shape[1] - time_mask_width)\n",
    "                    phase_randomized[:, time_mask_start:time_mask_start + time_mask_width] = 0\n",
    "                    \n",
    "                    sig_phase_randomized = librosa.istft(np.abs(librosa.core.stft(sig, n_fft=400, hop_length=160, win_length=400, window='hann')) * np.exp(1j * phase_randomized))\n",
    "                    \n",
    "                     \n",
    "                    if feats_type == 'mfcc':\n",
    "                        mfcc_feat = mfcc(sig_phase_randomized, rate)\n",
    "                        mfcc_feat_delta = delta(mfcc_feat, 2)\n",
    "                        mfcc_feat_delta_delta = delta(mfcc_feat_delta, 2)\n",
    "                        feats = np.concatenate((mfcc_feat, mfcc_feat_delta, mfcc_feat_delta_delta), axis=1)\n",
    "                        \n",
    "                    else: # fbank\n",
    "                        filters, energy = fbank(sig_phase_randomized, rate, nfilt=40)\n",
    "                        log_filters, log_energy = np.log(filters), np.log(energy)\n",
    "                        logfbank_feat = np.concatenate((log_filters, log_energy.reshape(-1,1)), axis=1)\n",
    "                        logfbank_feat_delta = delta(logfbank_feat, 2)\n",
    "                        logfbank_feat_delta_delta = delta(logfbank_feat_delta, 2)\n",
    "                        feats = np.concatenate((logfbank_feat, logfbank_feat_delta, logfbank_feat_delta_delta), axis=1)\n",
    "                    \n",
    "                    feats_list.append(feats)\n",
    "\n",
    "                    # .phn\n",
    "                    phoneme = []\n",
    "                    with open(fnameNoSuffix + '.phn', 'r') as f:\n",
    "                        for line in f.read().splitlines():\n",
    "                            phn = line.split(' ')[2]\n",
    "                            p_index = phn_61.index(phn)\n",
    "                            phoneme.append(p_index)\n",
    "                    phoneme_list.append(phoneme)\n",
    "\n",
    "                    cnt += 1\n",
    "\n",
    "        if fname == 'train':\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(np.concatenate(feats_list, axis=0))\n",
    "            print('scaler.n_samples_seen_:', scaler.n_samples_seen_)\n",
    "            pickle.dump(scaler, open(os.path.join(tfrecord_path, 'scaler.pkl'), 'wb'))\n",
    "            \n",
    "        if not os.path.exists(os.path.join(tfrecord_path, 'scaler.pkl')):\n",
    "            raise Exception('scaler.pkl not exist, call with [train_set=True]')\n",
    "        else:\n",
    "            scaler = pickle.load(open(os.path.join(tfrecord_path, 'scaler.pkl'), 'rb'))\n",
    "        \n",
    "        for feats, phoneme in zip(feats_list, phoneme_list):\n",
    "            seq_exam = tf.train.SequenceExample()\n",
    "            seq_exam.context.feature['feats_dim'].int64_list.value.append(feats.shape[1])\n",
    "            seq_exam.context.feature['feats_seq_len'].int64_list.value.append(feats.shape[0])\n",
    "            seq_exam.context.feature['labels_seq_len'].int64_list.value.append(len(phoneme))\n",
    "\n",
    "            feats = scaler.transform(feats)\n",
    "            for feat in feats:\n",
    "                seq_exam.feature_lists.feature_list['features'].feature.add().float_list.value[:] = feat\n",
    "            for p in phoneme:\n",
    "                seq_exam.feature_lists.feature_list['labels'].feature.add().int64_list.value.append(p)\n",
    "            writer.write(seq_exam.SerializeToString())\n",
    "\n",
    "        writer.close()\n",
    "        print('{} created: {} utterances - {:.0f}s'.format(fname+'.tfrecords', cnt, (time.time()-start)))\n",
    "    # end create_tfrecords() definition\n",
    "    \n",
    "    tfrecord_path = os.path.join(TFRECORD_DIR, feats_type)\n",
    "    if not os.path.isdir(tfrecord_path):\n",
    "        os.makedirs(tfrecord_path)\n",
    "    \n",
    "    if train_set:\n",
    "        create_tfrecords(tfrecord_path, os.path.join(TIMIT_DIR, 'TIMIT(wav)/TRAIN'), 'train',\n",
    "                         lambda file, _: file.startswith('SA'))\n",
    "    if dev_set:\n",
    "        create_tfrecords(tfrecord_path, os.path.join(TIMIT_DIR, 'TIMIT(wav)/TEST'), 'dev', \n",
    "                         lambda file, path: file.startswith('SA') or os.path.split(path)[1] not in development_set)\n",
    "    if test_set:\n",
    "        create_tfrecords(tfrecord_path, os.path.join(TIMIT_DIR, 'TIMIT(wav)/TEST'), 'test', \n",
    "                         lambda file, path: file.startswith('SA') or os.path.split(path)[1] not in core_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaler.n_samples_seen_: 702601\n",
      "train.tfrecords created: 3696 utterances - 167s\n",
      "dev.tfrecords created: 392 utterances - 18s\n",
      "test.tfrecords created: 176 utterances - 8s\n"
     ]
    }
   ],
   "source": [
    "prepare_timit_dataset(feats_type='fbank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"model\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "f = zipfile.ZipFile(\"./TIMIT(wav).zip\",'r') \n",
    "\n",
    "for file in f.namelist():\n",
    "    f.extract(file,\"./\") \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
